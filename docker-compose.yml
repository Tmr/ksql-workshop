---
version: '2'

services:

#  broker:
#    image: confluentinc/cp-kafka:7.1.0
#    hostname: broker
#    container_name: broker
#    depends_on:
#      - zookeeper
#    ports:
#      - "29092:29092"
#      - "9092:9092"
#      - "9101:9101"
#    environment:
#      KAFKA_BROKER_ID: 1
#      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
#      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
#      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
#      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
#      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
#      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
#      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
#      KAFKA_JMX_PORT: 9101
#      KAFKA_JMX_HOSTNAME: localhost


  broker:
    image: confluentinc/cp-kafka:7.1.1
    hostname: broker
    container_name: broker
    ports:
      - "9092:9092"
      - "9101:9101"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@broker:29093'
      KAFKA_LISTENERS: 'PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
    volumes:
      - ./update_run.sh:/tmp/update_run.sh
    command: "bash -c 'if [ ! -f /tmp/update_run.sh ]; then echo \"ERROR: Did you forget the update_run.sh file that came with this docker-compose.yml file?\" && exit 1 ; else /tmp/update_run.sh && /etc/confluent/docker/run ; fi'"


#  schema-registry:
#    image: confluentinc/cp-schema-registry:7.1.0
#    hostname: schema-registry
#    container_name: schema-registry
#    depends_on:
#      - zookeeper
#      - broker
#    ports:
#      - "8081:8081"
#    environment:
#      SCHEMA_REGISTRY_HOST_NAME: schema-registry
#      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:29092'
#      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
#      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: 'zookeeper:2181'

#  connect:
#    image: confluentinc/cp-kafka-connect-base:7.1.0
#    hostname: connect
#    container_name: connect
#    depends_on:
#      - broker
##      - schema-registry
#    ports:
#      - "8083:8083"
#    environment:
#      CONNECT_BOOTSTRAP_SERVERS: 'broker:29092'
#      #SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: 'zookeeper:2181'
#      CONNECT_REST_ADVERTISED_HOST_NAME: connect
#      CONNECT_GROUP_ID: compose-connect-group
#      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
#      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
#      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
#      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
#      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
#      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
#      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
#      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
#      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
##      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
#      CONNECT_PLUGIN_PATH: "/usr/share/java/,/usr/share/confluent-hub-components/,/data/connect-jars/"
#      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR
#    volumes:
#      - $PWD/connector-components:/data/connect-jars

  ksqldb-server:
    image: confluentinc/ksqldb-server:0.26.0
    hostname: ksqldb-server
    container_name: ksqldb-server
    depends_on:
      - broker
#      - schema-registry
#      - connect
    ports:
      - "8088:8088"
      - "8083:8083" # Embedded Connect endpoint
    volumes:
      - "./connector-components:/usr/share/kafka/plugins"
    environment:
      KSQL_CONFLUENT_SUPPORT_METRICS_ENABLE: false #confluent.support.metrics.enable
      KSQL_LISTENERS: "http://0.0.0.0:8088"
      KSQL_BOOTSTRAP_SERVERS: "broker:29092"
#      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      KSQL_KSQL_SUPPRESS_ENABLED: "true"
      KSQL_COMMIT_INTERVAL_MS: 0
#      KSQL_KSQL_CONNECT_URL: http://connect:8083
      # Configuration to embed Kafka Connect support.
      KSQL_CONNECT_GROUP_ID: "ksql-connect-cluster"
      KSQL_CONNECT_BOOTSTRAP_SERVERS: "broker:29092"

      #KSQL_CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      #KSQL_CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      KSQL_CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      KSQL_CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      KSQL_CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      KSQL_CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"

#      KSQL_CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
#      KSQL_CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"

      KSQL_CONNECT_CONFIG_STORAGE_TOPIC: "ksql-connect-configs"
      KSQL_CONNECT_OFFSET_STORAGE_TOPIC: "ksql-connect-offsets"
      KSQL_CONNECT_STATUS_STORAGE_TOPIC: "ksql-connect-statuses"
      KSQL_CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      KSQL_CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      KSQL_CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      KSQL_CONNECT_PLUGIN_PATH: "/usr/share/kafka/plugins"
#      CLASSPATH: "/usr/share/kafka/plugins/bconnector-1.0-SNAPSHOT-jar-with-dependencies.jar"

  ksqldb-cli:
    image: confluentinc/ksqldb-cli:0.26.0
    container_name: ksqldb-cli
    depends_on:
      - ksqldb-server
    entrypoint: /bin/sh
    tty: true
    volumes:
      - "./sql:/sql"
    environment:
        KSQL_COMMIT_INTERVAL_MS: 0


#  kcat:
#    image: edenhill/kcat:1.7.1
#    container_name: kcat
#    depends_on:
#      - broker
#    entrypoint: /bin/sh
#    tty: true

#  kafka-ui:
#    container_name: kafka-ui
#    image: provectuslabs/kafka-ui:latest
#    ports:
#      - 8080:8080
#    depends_on:
#      - zookeeper
#      - broker
##      - schema-registry
##      - connect
#      - ksqldb-server
#    environment:
#      KAFKA_CLUSTERS_0_NAME: local
#      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: broker:29092
#      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
#      KAFKA_CLUSTERS_0_JMXPORT: 9997
##      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8085
#      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: connect
##      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://connect:8083
#      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://ksqldb-server:8088
#      KAFKA_CLUSTERS_0_KSQLDBSERVER: http://ksqldb-server:8088

  control-center:
    image: confluentinc/cp-enterprise-control-center:7.1.1
    hostname: control-center
    container_name: control-center
    depends_on:
      - broker
      - ksqldb-server
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:29092'
      #CONTROL_CENTER_CONNECT_CONNECT-DEFAULT_CLUSTER: 'connect:8083'
      CONTROL_CENTER_KSQL_KSQLDB1_URL: "http://ksqldb-server:8088"
      CONTROL_CENTER_KSQL_KSQLDB1_ADVERTISED_URL: "http://localhost:8088"
      #CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      PORT: 9021

#  elasticsearch:
#    image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.10.0
#    container_name: elasticsearch
#    #restart: always
#    healthcheck:
#      start_period: 10s
#      interval: 10s
#      retries: 20
#      test: curl -s http://localhost:9200/_cluster/health | grep -vq '"status":"red"'
#    ports:
#      - 9200:9200
#      - 9300:9300
#    environment:
#      discovery.type: "single-node"
#      ES_JAVA_OPTS: "-Xms1g -Xmx1g"
#      cluster.name: "elasticsearch-demo"

#  kibana:
#    image: docker.elastic.co/kibana/kibana-oss:7.10.0
#    container_name: kibana
#    restart: always
#    healthcheck:
#      interval: 10s
#      retries: 20
#      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://kibana:5601/api/status || exit 1
#    depends_on:
#      elasticsearch:
#        condition: service_healthy
#    ports:
#      - 5601:5601
#    environment:
#      NEWSFEED_ENABLED: 'false'
#      TELEMETRY_OPTIN: 'false'
#      TELEMETRY_ENABLED: 'false'
#      SERVER_MAXPAYLOADBYTES: 4194304
#      KIBANA_AUTOCOMPLETETIMEOUT: 3000
#      KIBANA_AUTOCOMPLETETERMINATEAFTER: 2500000
